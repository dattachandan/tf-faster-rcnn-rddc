{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangwenzhe/tf-faster-rcnn/python3_env/lib/python3.4/importlib/_bootstrap.py:321: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/wangwenzhe/tf-faster-rcnn/python3_env/lib/python3.4/importlib/_bootstrap.py:321: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/wangwenzhe/tf-faster-rcnn/python3_env/lib/python3.4/importlib/_bootstrap.py:321: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "from imgaug import augmenters as iaa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT_DIR = '/home/wangwenzhe/tf-faster-rcnn-rddc'\n",
    "ANALYSIS_DIR = os.path.join(ROOT_DIR, 'analysis')\n",
    "IMAGE_DIR = '/home/wangwenzhe/tf-faster-rcnn-rddc/data/VOCdevkit2007/VOC2007/JPEGImages/'\n",
    "ANNO_DIR = '/home/wangwenzhe/tf-faster-rcnn-rddc/data/VOCdevkit2007/VOC2007/Annotations/'\n",
    "TXT_DIR = '/home/wangwenzhe/tf-faster-rcnn-rddc/data/VOCdevkit2007/VOC2007/ImageSets/Main/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'window_file_voc2007_trainval.txt'\n",
    "\n",
    "# load the annotations\n",
    "bboxs = []\n",
    "anno_dict = {}\n",
    "with open(os.path.join(ANALYSIS_DIR, file_name)) as f:\n",
    "    im_name = f.readline().strip()\n",
    "    while(im_name):\n",
    "        obj_num = int(f.readline().strip())\n",
    "        for i in range(obj_num):\n",
    "            bboxs.append(f.readline().strip().split(' '))\n",
    "        anno_dict[im_name] = bboxs[-obj_num:] if obj_num > 0 else []\n",
    "        im_name = f.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures: 7240 + 2400 = 9640\n",
      "Number of pictures (each class): [2679, 3732, 1182, 1032, 2444, 1268, 1312, 3540]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CLASSES = ('d00', 'd01', 'd10', 'd11', 'd20', 'd40', 'd43', 'd44')\n",
    "\n",
    "# suppose we augment the data of class 3, 4, 6, 7\n",
    "do_aug = 0\n",
    "aug_num = 0\n",
    "for im_name in anno_dict:\n",
    "    for bbox in anno_dict[im_name]:\n",
    "        if int(bbox[0]) in [3,4,7]:\n",
    "            do_aug = 1 if do_aug < 1 else do_aug # 2 times\n",
    "        elif int(bbox[0]) in [6]:\n",
    "            do_aug = 3 if do_aug < 3 else do_aug # 4 times\n",
    "    for bbox in anno_dict[im_name]:\n",
    "        for i in range(do_aug):\n",
    "            bboxs.append(bbox)\n",
    "    aug_num += do_aug\n",
    "    do_aug = 0\n",
    "print('Number of pictures: {} + {} = {}'.format(len(anno_dict), aug_num, len(anno_dict) + aug_num))\n",
    "    \n",
    "# number of pictures after augmentation (each class)\n",
    "class_num = [0 for i in range(8)]\n",
    "for b in bboxs:\n",
    "    class_num[int(b[0]) - 1] += 1\n",
    "print('Number of pictures (each class): {}'.format(class_num))\n",
    "plt.bar(CLASSES, class_num, 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the training data\n",
    "seq = iaa.OneOf([\n",
    "    iaa.ContrastNormalization((1.2,2)),\n",
    "    iaa.ContrastNormalization(0.5,0.7),\n",
    "    iaa.Multiply((1.2,1.5)),\n",
    "    iaa.Multiply((0.5,0.7)),\n",
    "    iaa.GaussianBlur((0.8,1.2))\n",
    "])\n",
    "\n",
    "seq_cont = iaa.OneOf([\n",
    "    iaa.ContrastNormalization((1.2,2)),\n",
    "    iaa.ContrastNormalization(0.5,0.7)\n",
    "])\n",
    "\n",
    "seq_mult = iaa.OneOf([\n",
    "    iaa.Multiply((1.2,1.5)),\n",
    "    iaa.Multiply((0.5,0.7))\n",
    "])\n",
    "\n",
    "seq_guas = iaa.OneOf([\n",
    "    iaa.GaussianBlur((0.8,1.2))\n",
    "])\n",
    "\n",
    "images = glob(IMAGE_DIR + 'train_[A-Z]*.jpg')\n",
    "images.sort()\n",
    "do_aug = 0\n",
    "count = 0\n",
    "for im_name in images:\n",
    "    for bbox in anno_dict[im_name]:\n",
    "        if int(bbox[0]) in [3,4,7]:\n",
    "            do_aug = 1 if do_aug < 1 else do_aug # 2 times\n",
    "        elif int(bbox[0]) in [6]:\n",
    "            do_aug = 3 if do_aug < 3 else do_aug # 4 times\n",
    "    im = cv2.imread(im_name)\n",
    "    anno = im_name.replace('JPEGImages', 'Annotations').replace('jpg', 'xml')\n",
    "    if do_aug == 1:\n",
    "        im_aug0 = seq.augment_image(im)\n",
    "        cv2.imwrite(im_name.replace('train', 'train_aug0'), im_aug0)\n",
    "        with open(anno) as fr, open(anno.replace('train', 'train_aug0'),'w') as fw:\n",
    "            fw.write(fr.read().replace('train', 'train_aug0'))\n",
    "    elif do_aug == 3:\n",
    "        im_aug1 = seq_cont.augment_image(im)\n",
    "        cv2.imwrite(im_name.replace('train', 'train_aug1'), im_aug1)\n",
    "        with open(anno) as fr, open(anno.replace('train', 'train_aug1'),'w') as fw:\n",
    "            fw.write(fr.read().replace('train', 'train_aug1'))\n",
    "        im_aug2 = seq_mult.augment_image(im)\n",
    "        cv2.imwrite(im_name.replace('train', 'train_aug2'), im_aug2)\n",
    "        with open(anno) as fr, open(anno.replace('train', 'train_aug2'),'w') as fw:\n",
    "            fw.write(fr.read().replace('train', 'train_aug2'))\n",
    "        im_aug3 = seq_guas.augment_image(im)\n",
    "        cv2.imwrite(im_name.replace('train', 'train_aug3'), im_aug3)\n",
    "        with open(anno) as fr, open(anno.replace('train', 'train_aug3'),'w') as fw:\n",
    "            fw.write(fr.read().replace('train', 'train_aug3'))\n",
    "    count += do_aug\n",
    "    do_aug = 0\n",
    "    print(str(count) + ' / ' + str(aug_num), end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update trainval.txt\n",
    "train_images = glob(IMAGE_DIR + 'train*.jpg')\n",
    "with open(TXT_DIR + 'trainval.txt', 'w') as f:\n",
    "    for im_name in train_images:\n",
    "        f.write(im_name.split('/')[-1].split('.')[0] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tools that may be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Validity the verify of training data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change test.txt to augmented data in trainval.txt\n",
    "train_aug_images = glob(IMAGE_DIR + 'train_aug*.jpg')\n",
    "with open(TXT_DIR + 'test.txt', 'w') as f:\n",
    "    for im_name in train_aug_images:\n",
    "        f.write(im_name.split('/')[-1].split('.')[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change test.txt to original data in trainval.txt\n",
    "train_images = glob(IMAGE_DIR + 'train_[A-Z]*.jpg')\n",
    "train_images.sort()\n",
    "with open(TXT_DIR + 'test.txt', 'w') as f:\n",
    "    for im_name in train_images:\n",
    "        f.write(im_name.split('/')[-1].split('.')[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test on the above datasets using existing model separately, then compare the mAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Test data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment the test data\n",
    "seq = iaa.OneOf([\n",
    "    iaa.ContrastNormalization((1.2,2)),\n",
    "    iaa.ContrastNormalization(0.5,0.7),\n",
    "    iaa.Multiply((1.2,1.5)),\n",
    "    iaa.Multiply((0.5,0.7)),\n",
    "    iaa.GaussianBlur((0.8,1.2))\n",
    "])\n",
    "\n",
    "images = glob(IMAGE_DIR + 'test_[A-Z]*.jpg')\n",
    "for im_name in images:\n",
    "    print(str(images.index(im_name) + 1) + ' / ' + str(len(images)), end='\\r', flush=True)\n",
    "    im = cv2.imread(im_name)\n",
    "    im_aug = seq.augment_image(im)\n",
    "    cv2.imwrite(im_name.replace('test', 'test_aug'), im_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update test.txt\n",
    "test_images = glob(IMAGE_DIR + 'test*.jpg')\n",
    "with open(TXT_DIR + 'test.txt', 'w') as f:\n",
    "    for im_name in test_images:\n",
    "        f.write(im_name.split('/')[-1].split('.')[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then use some way to get more robust results using the augmented test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Delete the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete the augmented training data\n",
    "os.system('rm ' + IMAGE_DIR + 'train_aug*.jpg')\n",
    "os.system('rm ' + ANNO_DIR + 'train_aug*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete the augmented test data\n",
    "os.system('rm ' + IMAGE_DIR + 'test_aug*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
